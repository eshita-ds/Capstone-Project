{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import transformers\n",
                "import evaluate\n",
                "import chromadb\n",
                "import random\n",
                "import torch\n",
                "\n",
                "from IPython.display import display, Markdown\n",
                "from tqdm import tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SEED = 42\n",
                "random.seed(SEED)\n",
                "_ = torch.manual_seed(SEED)\n",
                "DEVICE = (\n",
                "    torch.device(\"cuda\")\n",
                "    if torch.cuda.is_available()\n",
                "    else (\n",
                "        torch.device(\"mps\")\n",
                "        if torch.backends.mps.is_available()\n",
                "        else torch.device(\"cpu\")\n",
                "    )\n",
                ")\n",
                "# QUANTIZATION = (\n",
                "#     transformers.BitsAndBytesConfig(load_in_8bit=True)\n",
                "#     if torch.cuda.is_available()\n",
                "#     else (\n",
                "#         transformers.QuantoConfig(weights=\"int8\")\n",
                "#         if torch.backends.mps.is_available()\n",
                "#         else None\n",
                "#     )\n",
                "# )\n",
                "QUANTIZATION = None\n",
                "MODEL_NAME = \"microsoft/Phi-3.5-mini-instruct\"\n",
                "MAX_NEW_TOKENS = 1000\n",
                "ROUGE = evaluate.load(\"rouge\")\n",
                "BLEU = evaluate.load(\"bleu\")\n",
                "K = 5\n",
                "CLIENT = chromadb.PersistentClient()\n",
                "COLLECTION = CLIENT.create_collection(\"MATH\", get_or_create=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data = pd.read_csv(\"MATH_train_staging.csv\")\n",
                "test_data = pd.read_csv(\"MATH_test_staging.csv\")\n",
                "val_data = pd.read_csv(\"MATH_val_staging.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "display(Markdown(train_data.loc[0][\"question_text\"]))\n",
                "display(Markdown(train_data.loc[0][\"reasoning\"]))\n",
                "display(Markdown(train_data.loc[0][\"answer\"]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# for idx, row in tqdm(train_data.iterrows(), desc=\"populating vector db\"):\n",
                "#     COLLECTION.add(\n",
                "#         documents=[row[\"question_text\"]],\n",
                "#         metadatas=[{\"reasoning\": row[\"reasoning\"], \"answer\": row[\"answer\"]}],\n",
                "#         ids=[f\"{row['dataset_id']}_{row['question_id']}\"],\n",
                "#     )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "llm = transformers.AutoModelForCausalLM.from_pretrained(\n",
                "    MODEL_NAME,\n",
                "    device_map=DEVICE,\n",
                "    torch_dtype=\"auto\",\n",
                "    quantization_config=QUANTIZATION,\n",
                "    trust_remote_code=True,\n",
                ")\n",
                "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
                "    MODEL_NAME, trust_remote_code=True\n",
                ")\n",
                "pipe = transformers.pipeline(\n",
                "    task=\"text-generation\",\n",
                "    model=llm,\n",
                "    tokenizer=tokenizer,\n",
                "    device_map=DEVICE,\n",
                "    trust_remote_code=True,\n",
                ")\n",
                "generation_args = {\n",
                "    \"max_new_tokens\": MAX_NEW_TOKENS,\n",
                "    \"temperature\": 0.0,\n",
                "    \"do_sample\": False,\n",
                "}\n",
                "llm.eval()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_neighbors(text, start):\n",
                "    results = COLLECTION.query(query_texts=text, n_results=K + start)\n",
                "    neighbors = []\n",
                "    for i in range(start, K + start):\n",
                "        neighbor = {\n",
                "            \"question\": results[\"documents\"][0][i],\n",
                "            \"reasoning\": results[\"metadatas\"][0][i][\"reasoning\"],\n",
                "            \"answer\": results[\"metadatas\"][0][i][\"answer\"],\n",
                "        }\n",
                "        neighbors.append(neighbor)\n",
                "    return neighbors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_prompt(text, start):\n",
                "    message = []\n",
                "    neighbors = get_neighbors(text, start)\n",
                "    for neighbor in neighbors:\n",
                "        message.append({\"role\": \"user\", \"content\": neighbor[\"question\"]})\n",
                "        message.append(\n",
                "            {\n",
                "                \"role\": \"assistant\",\n",
                "                \"content\": f\"{neighbor['reasoning']}\\n\\n{neighbor['answer']}\",\n",
                "            }\n",
                "        )\n",
                "    message.append({\"role\": \"user\", \"content\": text})\n",
                "    return message"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt = get_prompt(train_data.loc[0][\"question_text\"], 1)\n",
                "prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response = pipe(prompt, **generation_args)[0][\"generated_text\"][-1][\"content\"].strip()\n",
                "display(Markdown(response.replace(\"\\n\", \"\\n\\n\")))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "val_results = {\n",
                "    \"dataset_id\": [],\n",
                "    \"question_id\": [],\n",
                "    \"bleu\": [],\n",
                "    \"rouge1\": [],\n",
                "    \"rouge2\": [],\n",
                "    \"rougeL\": [],\n",
                "    \"response\": [],\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for idx in tqdm(range(len(val_data)), desc=\"evaluating\"):\n",
                "    row = val_data.loc[idx]\n",
                "    val_results[\"dataset_id\"].append(row[\"dataset_id\"])\n",
                "    val_results[\"question_id\"].append(row[\"question_id\"])\n",
                "    prompt = get_prompt(row[\"question_text\"], 0)\n",
                "    response = pipe(prompt, **generation_args)[0][\"generated_text\"][-1][\n",
                "        \"content\"\n",
                "    ].strip()\n",
                "    val_results[\"response\"].append(response)\n",
                "    bleu = BLEU.compute(\n",
                "        predictions=[response], references=[[row[\"reasoning\"], row[\"answer\"]]]\n",
                "    )\n",
                "    val_results[\"bleu\"].append(bleu[\"bleu\"])\n",
                "    rouge = ROUGE.compute(\n",
                "        predictions=[response],\n",
                "        references=[[row[\"reasoning\"], row[\"answer\"]]],\n",
                "        tokenizer=lambda x: x.split(),\n",
                "    )\n",
                "    val_results[\"rouge1\"].append(rouge[\"rouge1\"])\n",
                "    val_results[\"rouge2\"].append(rouge[\"rouge2\"])\n",
                "    val_results[\"rougeL\"].append(rouge[\"rougeL\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.DataFrame(val_results).to_csv(\n",
                "    f\"{MODEL_NAME.split(\"/\")[1]}_MATH_{K}_shot_val_results.csv\", index=False\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}